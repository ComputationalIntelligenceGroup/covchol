% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/prxgradl.R
\name{prxgradchol}
\alias{prxgradchol}
\alias{cholpath}
\title{Penalized likelihood estimation of Cholesky factor}
\usage{
prxgradchol(
  Sigma,
  L,
  eps = 0.01,
  alpha = 0.5,
  maxIter = 100,
  lambda = 0,
  job = 1
)

cholpath(
  Sigma,
  lambdas = NULL,
  L = diag(nrow(Sigma)),
  eps = 1e-08,
  maxIter = 1000
)
}
\arguments{
\item{Sigma}{the empirical covariance matrix}

\item{L}{initial cholesky factor}

\item{eps}{convergence threshold for the proximal gradient}

\item{alpha}{line search rate}

\item{maxIter}{the maximum number of iterations}

\item{lambda}{penalization coefficient}

\item{job}{if 0 no additional zeros will be imposed}

\item{lambdas}{increasing sequence of lambdas}
}
\value{
a list with the output of the optimization:

* \code{N}
* \code{L} the estimated L matrix
* \code{lambda} 
* \code{diff} the value of the last relative decrease
* \code{objective} the value of the objective function
* \code{iter} number of iterations
}
\description{
Solve the following optimization problem
\deqn{\hat{L} = \arg \min_{L} 2\log(det(L)) + tr(L^{-t}L^{-1} \Sigma)} + ||L||_1,off
}
\details{
\code{cholpath} returns the path of regularized estimator on a sequence of 
\code{lambda} parameters
}
